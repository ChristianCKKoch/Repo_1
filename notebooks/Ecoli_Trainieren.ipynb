{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Chris\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "Bestes Model ist: random forest mit einer Akkuranz von 88.05970149253731%\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import itemgetter, attrgetter\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.data.Preprocessor import Preprocessor\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        #Array für alle Ergebnisse\n",
    "        self.ergebnis = []\n",
    "    \n",
    "    def train_models(self, X_train, X_test, y_train, y_test, models):\n",
    "        for self.model in models:\n",
    "            #-----------------------\n",
    "            #Knn-Classifier\n",
    "            #-----------------------\n",
    "            if self.model == 'knn':\n",
    "                #Optimalen Knn-Classifier bestimmen\n",
    "                error = []\n",
    "                for i in range(1, 40):\n",
    "                    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "                    knn.fit(X_train, y_train)\n",
    "                    pred_i = knn.predict(X_test)\n",
    "                    error.append(np.mean(pred_i != y_test))\n",
    "\n",
    "                #Knn-Classifier trainieren\n",
    "                knnclf = KNeighborsClassifier(n_neighbors=7)\n",
    "                knnclf.fit(X_train, y_train)\n",
    "\n",
    "                #Knn-Classifier Akkuranz bestimmen\n",
    "                score = knnclf.score(X_test,y_test)\n",
    "                self.ergebnis.append(['knn-classifier', score, knnclf])\n",
    "            #-----------------------\n",
    "                \n",
    "            #-----------------------\n",
    "            #Decision Tree\n",
    "            #-----------------------\n",
    "            elif self.model == 'dt':\n",
    "                #class_weight gebrauchen für DT und RF\n",
    "\n",
    "                #Optimalen Decision Tree bestimmen\n",
    "                #Zu testende Decision Tree Parameter\n",
    "                dt = DecisionTreeClassifier()\n",
    "                tree_para = {'criterion':['gini','entropy'],'max_depth':[i for i in range(1,20)], 'min_samples_split':[i for i in range (2,20)]}\n",
    "\n",
    "                #GridSearchCV \n",
    "                grd_clf = GridSearchCV(dt, tree_para, cv=5)\n",
    "                grd_clf.fit(X_train, y_train)\n",
    "\n",
    "                #Besten gefundenen Decision Tree übergeben\n",
    "                dt_clf = grd_clf.best_estimator_\n",
    "\n",
    "                score = dt_clf.score(X_test,y_test)\n",
    "                self.ergebnis.append(['decision tree', score, dt_clf])\n",
    "            #-----------------------\n",
    "\n",
    "            #-----------------------\n",
    "            #Random Forest\n",
    "            #-----------------------\n",
    "            elif self.model == 'rf':\n",
    "                #rf = RandomForestClassifier(max_depth=8, criterion=\"entropy\", min_samples_split=9)\n",
    "                rf = RandomForestClassifier(n_estimators=100)\n",
    "                rf.fit(X_train,y_train)\n",
    "                score = rf.score(X_test,y_test)\n",
    "                self.ergebnis.append(['random forest', score, rf])\n",
    "            #-----------------------\n",
    "\n",
    "            #-----------------------\n",
    "            #Support Vector Machine\n",
    "            #-----------------------\n",
    "            elif self.model == 'svm':\n",
    "                svm = SVC(kernel = 'poly')\n",
    "                svm.fit(X_train, y_train)\n",
    "                score = svm.score(X_test,y_test)\n",
    "                self.ergebnis.append(['support vector machine', score, svm])\n",
    "\n",
    "        return self.ergebnis\n",
    "\n",
    "def get_classifier():\n",
    "    #Daten einlesen\n",
    "    data = pd.read_excel('../data/raw/U bung kNN Klassifizierung Ecoli.xlsx', sheet_name=0)\n",
    "    X = data.loc[:,data.columns != \"Target\"]\n",
    "    y = data[\"Target\"]\n",
    "\n",
    "    #Models spezifieren\n",
    "    models = {\"rf\":RandomForestClassifier, \"dt\":DecisionTreeClassifier, \"knn\":KNeighborsClassifier, \"svm\":SVC}\n",
    "\n",
    "    #Daten preprocessen\n",
    "    X_train, X_test, y_train, y_test = Preprocessor(X, y).get_data()\n",
    "\n",
    "    #Classifier verwenden\n",
    "    clf = Classifier()\n",
    "    resultat = clf.train_models(X_train, X_test, y_train, y_test, models)\n",
    "    \n",
    "    #Bestes Ergebnis bestimmen und als Modell verwenden\n",
    "    print(\"Bestes Model ist: {} mit einer Akkuranz von {}%\".format(sorted(resultat, key=itemgetter(1), reverse=True)[0][0],sorted(resultat, key=itemgetter(1), reverse=True)[0][1]*100))\n",
    "    return sorted(resultat, key=itemgetter(1), reverse=True)[0][2]\n",
    "\n",
    "\n",
    "print(get_classifier())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'ergebnis' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-654dc88c5e10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mergebnis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ergebnis' is not defined"
     ]
    }
   ],
   "source": [
    "sorted(ergebnis, key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd0e660af3098993ea5160fd9270f74e6db286e749e474b6bbf115c5a1892218496",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}